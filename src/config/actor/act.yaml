# Extend the base_actor config
defaults:
  - base_actor

name: act

action_horizon: 32
pred_horizon: 8
obs_horizon: 1
predict_past_actions: ${predict_past_actions}

optimization:
  ewise_reconstruction_loss_fn: l1_loss # Any loss implemented by torch.nn.functional (eg. l1_loss, l2_loss) etc..
  beta_kl: 10

inference:
  temporal_ensemble_m: 0.01

# TODO: Move to a model config, specify default in this config
ConditionalVAE:
  dim_state: 58
  dim_latent: 32
  dim_action: 10
  action_chunk_size: ${pred_horizon}

  TransformerEncoder:
    num_layers: 4
    layer_norm: True

    TransformerEncoderLayer:
      dim_model: 256
      num_heads: 8
      dim_feedforward: 2048
      dropout: 0.1
      activation: relu # Can specify any activation function implemented by torch.nn.functional
      normalize_before: False

  ActionTransformer:
    dim_model: 512  # Parent parameters such as 'dim_model' automatically propagate to and are shared by children of 'ActionTransformer' unless overriden.

    TransformerEncoder:
      num_layers: 6
      layer_norm: True
      TransformerEncoderLayer:
        num_heads: 8
        dim_feedforward: 2048
        dropout: 0.1
        activation: relu
        normalize_before: False

    TransformerDecoder:
      num_layers: 6
      TransformerDecoderLayer:
        num_heads: 8
        dim_feedforward: 2048
        dropout: 0.1
        activation: relu
        normalize_before: False









