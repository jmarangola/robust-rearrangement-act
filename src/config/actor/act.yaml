# Extend the base_actor config
defaults:
  - base_actor

name: act

flatten_obs: True # Why is this not in the base config?
action_horizon: 32
pred_horizon: 8
obs_horizon: 1
predict_past_actions: ${predict_past_actions}

ewise_reconstruction_loss_fn: l1_loss
beta_kl: 10

inference:
  temporal_ensemble_m: 0.01

# TODO: Move to a model config, specify default in this config
ConditionalVAE:
  dim_robot_state: 16 # ${robot_state_dim}
  dim_object_state: 42 # ${part_poses_dim}
  action_chunk_size: 8

  dim_latent: 32
  dim_action: 10

  TransformerEncoder:
    num_layers: 4
    layer_norm: True

    TransformerEncoderLayer:
      dim_model: 256
      num_heads: 8
      dim_feedforward: 2048
      dropout: 0.1
      activation: relu # Can specify any activation function implemented by torch.nn.functional
      normalize_before: False

  ActionTransformer:
    dim_model: 512  # Parent parameters such as 'dim_model' automatically propagate to and are shared by children of 'ActionTransformer' unless overriden.

    TransformerEncoder:
      num_layers: 6
      layer_norm: True
      TransformerEncoderLayer:
        num_heads: 8
        dim_feedforward: 2048
        dropout: 0.1
        activation: relu
        normalize_before: False

    TransformerDecoder:
      num_layers: 6
      TransformerDecoderLayer:
        num_heads: 8
        dim_feedforward: 2048
        dropout: 0.1
        activation: relu
        normalize_before: False









